{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e624dbc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"TASK_2.ipynb\n",
    "\n",
    "Automatically generated by Colab.\n",
    "\n",
    "Original file is located at\n",
    "    https://colab.research.google.com/drive/1MGWRWL7bfKgy7xZXXd5rm5vYH_NXFr__\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb49e894",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU CHECK\n",
    "import torch\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "else:\n",
    "    print(\"⚠ WARNING: No GPU detected. Go to Runtime → Change runtime type → Hardware accelerator → GPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499b3ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q diffusers transformers accelerate torch torchvision xformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53752d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from diffusers import StableDiffusionPipeline, DPMSolverMultistepScheduler\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7445230",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"runwayml/stable-diffusion-v1-5\"\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f752796",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = StableDiffusionPipeline.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=torch.float16,\n",
    "    safety_checker=None,\n",
    "    requires_safety_checker=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4140a43",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "pipe.scheduler = DPMSolverMultistepScheduler.from_config(pipe.scheduler.config)\n",
    "pipe = pipe.to(device)\n",
    "pipe.enable_attention_slicing()\n",
    "print(\"Model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73902000",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def generate_image(\n",
    "    prompt,\n",
    "    negative_prompt=\"blurry, low quality, distorted, ugly\",\n",
    "    width=512,\n",
    "    height=512,\n",
    "    num_inference_steps=20,\n",
    "    guidance_scale=7.5,\n",
    "    num_images=1,\n",
    "    seed=None\n",
    "):\n",
    "    if seed is not None:\n",
    "        generator = torch.Generator(device=device).manual_seed(seed)\n",
    "    else:\n",
    "        generator = None\n",
    "\n",
    "    print(f\"Generating {num_images} image(s)...\")\n",
    "    result = pipe(\n",
    "        prompt=prompt,\n",
    "        negative_prompt=negative_prompt,\n",
    "        width=width,\n",
    "        height=height,\n",
    "        num_inference_steps=num_inference_steps,\n",
    "        guidance_scale=guidance_scale,\n",
    "        num_images_per_prompt=num_images,\n",
    "        generator=generator\n",
    "    )\n",
    "    return result.images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca00458",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"A beautiful mountain landscape at sunset and birds, digital art highly detailed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77eab433",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = generate_image(prompt, num_images=1)\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.imshow(images[0])\n",
    "plt.axis('off')\n",
    "plt.title(f\"Generated: '{prompt}'\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b18e354",
   "metadata": {},
   "outputs": [],
   "source": [
    "images[0].save(\"my_image.png\")\n",
    "print(\" Image saved as 'my_image.png'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ab46cb",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "my_prompts = [\n",
    "    \"A futuristic city with flying cars,\",\n",
    "    \"A cute cat wearing sunglasses, cartoon style\",\n",
    "    \"A old man walk on the street in the morning time\","
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ca4562",
   "metadata": {},
   "outputs": [],
   "source": [
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91bb6d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, prompt in enumerate(my_prompts):\n",
    "    print(f\"\\n--- Generating {i+1} ---\")\n",
    "    images = generate_image(prompt, num_images=1)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(images[0])\n",
    "    plt.axis('off')\n",
    "    plt.title(f\"'{prompt}'\")\n",
    "    plt.show()\n",
    "    images[0].save(f\"my_image_{i+1}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2f36fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nuclear option - Completely fresh notebook\n",
    "!cp TASK_2.ipynb TASK_2_CLEAN.ipynb\n",
    "!python -c \"import json; data = {'cells': [], 'metadata': {}, 'nbformat': 4, 'nbformat_minor': 5}; json.dump(data, open('TASK_2_CLEAN.ipynb', 'w'), indent=2)\"\n",
    "print(\"✅ Fresh empty notebook created\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "encoding": "# -*- coding: utf-8 -*-",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
